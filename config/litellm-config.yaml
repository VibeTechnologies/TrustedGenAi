# =============================================================================
# TrustedGenAi LiteLLM Configuration
# =============================================================================
#
# Standalone LiteLLM config for TEE-hosted DeepSeek models.
# This config runs on the TEE VM itself, proxying requests to local Ollama.
#
# For billing integration with VibeBrowser subscriptions, see:
# https://github.com/AnomalyCo/vibe.3/services/subscription
#
# =============================================================================

model_list:
  # DeepSeek R1 1.5B - Primary model for CPU TEE
  # Performance: ~12 tokens/sec on DC4es_v5
  - model_name: deepseek-r1
    litellm_params:
      model: ollama/deepseek-r1:1.5b
      api_base: http://localhost:11434
    model_info:
      input_cost_per_token: 0
      output_cost_per_token: 0
      tee_enabled: true

  # DeepSeek R1 7B - Higher quality, slower inference
  # Performance: ~0.7 tokens/sec on DC4es_v5 (not recommended for production)
  - model_name: deepseek-r1-7b
    litellm_params:
      model: ollama/deepseek-r1:7b
      api_base: http://localhost:11434
    model_info:
      input_cost_per_token: 0
      output_cost_per_token: 0
      tee_enabled: true

  # Alias for compatibility with VibeBrowser extension
  - model_name: deepseek-r1-1.5b
    litellm_params:
      model: ollama/deepseek-r1:1.5b
      api_base: http://localhost:11434
    model_info:
      input_cost_per_token: 0
      output_cost_per_token: 0
      tee_enabled: true

# =============================================================================
# GPU TEE Models (when deployed on NCCads_H100_v5)
# =============================================================================
# Uncomment when running on GPU TEE infrastructure
#
#   - model_name: deepseek-r1-distill-7b
#     litellm_params:
#       model: openai/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
#       api_base: http://localhost:8000/v1
#       api_key: local
#     model_info:
#       input_cost_per_token: 0
#       output_cost_per_token: 0
#       tee_enabled: true
#       gpu_tee_enabled: true

# =============================================================================
# Settings
# =============================================================================

litellm_settings:
  drop_params: true
  # No telemetry for privacy
  telemetry: false

general_settings:
  # API key for external access (set via environment variable)
  master_key: os.environ/TEE_API_KEY
